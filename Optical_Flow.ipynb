{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optical Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO 1:\n",
    "Finish the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for Lucas-Kanade optical flow\n",
    "lk_params = dict( winSize = (15, 15), maxLevel = 2, criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "#TO-DO Read up on Lucas-Kanade Optical Flow. What parameters need to be set? Hint: This should be made as a dictionary.\n",
    "\n",
    "# Parameters for corner detection using Shi-Tomasi method\n",
    "feature_params = dict( maxCorners = 50, qualityLevel = 0.01, minDistance = 10, blockSize = 10)\n",
    "#TO-DO Read up on Shi-Tomasi method. What parameters need to be set? Hint: This should be made as a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables for tracking\n",
    "trajectory_len = 40      # Length of the trajectory\n",
    "detect_interval = 5      # Interval for detecting new features\n",
    "trajectories = []        # List to store trajectories\n",
    "frame_idx = 0            # Frame index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO 2:\n",
    "Finish the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'float' and 'builtin_function_or_method'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 65\u001b[0m\n\u001b[1;32m     63\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Calculate FPS\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m fps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m (\u001b[43mend\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Display FPS on the image\u001b[39;00m\n\u001b[1;32m     68\u001b[0m cv2\u001b[38;5;241m.\u001b[39mputText(img, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfps\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m FPS\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m30\u001b[39m), cv2\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_SIMPLEX, \u001b[38;5;241m1\u001b[39m, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'float' and 'builtin_function_or_method'"
     ]
    }
   ],
   "source": [
    "# Capture video from the first camera device\n",
    "cap = cv2.VideoCapture('testCV.mp4')\n",
    "p = None\n",
    "\n",
    "while True:\n",
    "    #Save the value of p from the previous iteration\n",
    "    if p != None:\n",
    "        old_p = p\n",
    "\n",
    "    # Store the start time to calculate FPS\n",
    "    start = time.time\n",
    "\n",
    "    # Read a new frame from the video capture\n",
    "    suc, frame = cap.read()\n",
    "    if not suc:\n",
    "        break  # Break if there is an issue reading the frame\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # Convert frame to grayscale\n",
    "    img = frame.copy()  # Create a copy of the frame for displaying results\n",
    "\n",
    "    # Calculate optical flow for the existing trajectories\n",
    "    if len(trajectories) > 0:\n",
    "        img0, img1 = prev_gray, frame_gray\n",
    "        #TO-DO\n",
    "        po, st, err = cv2.calcOpticalFlowPyrLK(prev_gray, frame_gray, old_p, None, **lk_params)\n",
    "        # Get the last points of trajectories\n",
    "        # Calculate forward optical flow\n",
    "        # Calculate backward optical flow\n",
    "        # Calculate difference between forward-backward flow\n",
    "        # Identify good points with small differences\n",
    "\n",
    "        new_trajectories = []\n",
    "\n",
    "        # TO-DO\n",
    "        # Update the trajectories with the new points and draw the new points on the image\n",
    "        # Make sure to trim down the trajectories when they get too long\n",
    "\n",
    "        trajectories = new_trajectories\n",
    "\n",
    "        # Draw the trajectories on the image\n",
    "        cv2.polylines(img, [np.int32(trajectory) for trajectory in trajectories], False, (0, 255, 0))\n",
    "        cv2.putText(img, 'track count: %d' % len(trajectories), (20, 50), cv2.FONT_HERSHEY_PLAIN, 1, (0,255,0), 2)\n",
    "\n",
    "    # Detect new features at specified intervals\n",
    "    if frame_idx % detect_interval == 0:\n",
    "        mask = np.zeros_like(frame_gray)  # Create an empty mask\n",
    "        mask[:] = 255  # Set all pixels to 255 (white)\n",
    "\n",
    "        # Mask out regions where features are already tracked\n",
    "        for x, y in [np.int32(trajectory[-1]) for trajectory in trajectories]:\n",
    "            cv2.circle(mask, (x, y), 5, 0, -1)  # Draw circles on the mask\n",
    "\n",
    "        # Detect good features to track\n",
    "        p = cv2.goodFeaturesToTrack(frame_gray, mask = mask, **feature_params)\n",
    "        if p is not None:\n",
    "            # Add new features to the trajectories\n",
    "            for x, y in np.float32(p).reshape(-1, 2):\n",
    "                trajectories.append([(x, y)])\n",
    "\n",
    "    frame_idx += 1  # Increment frame index\n",
    "    prev_gray = frame_gray  # Update previous frame\n",
    "\n",
    "    # End time to calculate FPS\n",
    "    end = time.time()\n",
    "    # Calculate FPS\n",
    "    fps = 1 / (end - start)\n",
    "    \n",
    "    # Display FPS on the image\n",
    "    cv2.putText(img, f\"{fps:.2f} FPS\", (20, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    # Show the image with optical flow\n",
    "    cv2.imshow('Optical Flow', img)\n",
    "    # Show the mask\n",
    "    cv2.imshow('Mask', mask)\n",
    "\n",
    "    # Exit on 'q' key press\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and destroy all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.4) ./modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     29\u001b[0m suc, frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m---> 30\u001b[0m frame_gray \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2GRAY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m img \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Calculate optical flow for a sparse feature set using the iterative Lucas-Kanade Method\u001b[39;00m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.4) ./modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "\n",
    "lk_params = dict(winSize  = (15, 15),\n",
    "                maxLevel = 2,\n",
    "                criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "feature_params = dict(maxCorners = 100,\n",
    "                    qualityLevel = 0.3,\n",
    "                    minDistance = 10,\n",
    "                    blockSize = 7 )\n",
    "\n",
    "\n",
    "trajectory_len = 40\n",
    "detect_interval = 5\n",
    "trajectories = []\n",
    "frame_idx = 0\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture('testCV.mp4')\n",
    "\n",
    "while True:\n",
    "\n",
    "    # start time to calculate FPS\n",
    "    start = time.time()\n",
    "\n",
    "    suc, frame = cap.read()\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    img = frame.copy()\n",
    "\n",
    "    # Calculate optical flow for a sparse feature set using the iterative Lucas-Kanade Method\n",
    "    if len(trajectories) > 0:\n",
    "        img0, img1 = prev_gray, frame_gray\n",
    "        p0 = np.float32([trajectory[-1] for trajectory in trajectories]).reshape(-1, 1, 2)\n",
    "        p1, _st, _err = cv2.calcOpticalFlowPyrLK(img0, img1, p0, None, **lk_params)\n",
    "        p0r, _st, _err = cv2.calcOpticalFlowPyrLK(img1, img0, p1, None, **lk_params)\n",
    "        d = abs(p0-p0r).reshape(-1, 2).max(-1)\n",
    "        good = d < 1\n",
    "\n",
    "        new_trajectories = []\n",
    "\n",
    "        # Get all the trajectories\n",
    "        for trajectory, (x, y), good_flag in zip(trajectories, p1.reshape(-1, 2), good):\n",
    "            if not good_flag:\n",
    "                continue\n",
    "            trajectory.append((x, y))\n",
    "            if len(trajectory) > trajectory_len:\n",
    "                del trajectory[0]\n",
    "            new_trajectories.append(trajectory)\n",
    "            # Newest detected point\n",
    "            cv2.circle(img, (int(x), int(y)), 2, (0, 0, 255), -1)\n",
    "\n",
    "        trajectories = new_trajectories\n",
    "\n",
    "        # Draw all the trajectories\n",
    "        cv2.polylines(img, [np.int32(trajectory) for trajectory in trajectories], False, (0, 255, 0))\n",
    "        cv2.putText(img, 'track count: %d' % len(trajectories), (20, 50), cv2.FONT_HERSHEY_PLAIN, 1, (0,255,0), 2)\n",
    "\n",
    "\n",
    "    # Update interval - When to update and detect new features\n",
    "    if frame_idx % detect_interval == 0:\n",
    "        mask = np.zeros_like(frame_gray)\n",
    "        mask[:] = 255\n",
    "\n",
    "        # Lastest point in latest trajectory\n",
    "        for x, y in [np.int32(trajectory[-1]) for trajectory in trajectories]:\n",
    "            cv2.circle(mask, (x, y), 5, 0, -1)\n",
    "\n",
    "        # Detect the good features to track\n",
    "        p = cv2.goodFeaturesToTrack(frame_gray, mask = mask, **feature_params)\n",
    "        if p is not None:\n",
    "            # If good features can be tracked - add that to the trajectories\n",
    "            for x, y in np.float32(p).reshape(-1, 2):\n",
    "                trajectories.append([(x, y)])\n",
    "\n",
    "\n",
    "    frame_idx += 1\n",
    "    prev_gray = frame_gray\n",
    "\n",
    "    # End time\n",
    "    end = time.time()\n",
    "    # calculate the FPS for current frame detection\n",
    "    fps = 1 / (end-start)\n",
    "    \n",
    "    # Show Results\n",
    "    cv2.putText(img, f\"{fps:.2f} FPS\", (20, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.imshow('Optical Flow', img)\n",
    "    cv2.imshow('Mask', mask)\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
